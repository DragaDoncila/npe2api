{
  "name": "napari-kld",
  "display_name": "Kernel Learning Deconvolution",
  "visibility": "public",
  "icon": "",
  "categories": [
    "Image Processing"
  ],
  "schema_version": "0.2.0",
  "on_activate": null,
  "on_deactivate": null,
  "contributions": {
    "commands": [
      {
        "id": "napari-kld.get_reader",
        "title": "Open data with Kernel Learning Deconvolution",
        "python_name": "napari_kld._reader:napari_get_reader",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari-kld.write_multiple",
        "title": "Save multi-layer data with Kernel Learning Deconvolution",
        "python_name": "napari_kld._writer:write_multiple",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari-kld.write_single_image",
        "title": "Save image data with Kernel Learning Deconvolution",
        "python_name": "napari_kld._writer:write_single_image",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari-kld.make_sample_data",
        "title": "Load sample data from Kernel Learning Deconvolution",
        "python_name": "napari_kld._sample_data:make_sample_data",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari-kld.rldwidget",
        "title": "RL Deconvolution",
        "python_name": "napari_kld:RLDwidget",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      },
      {
        "id": "napari-kld.kldwidget",
        "title": "KL Deconvolution",
        "python_name": "napari_kld:KLDwidget",
        "short_title": null,
        "category": null,
        "icon": null,
        "enablement": null
      }
    ],
    "readers": [
      {
        "command": "napari-kld.get_reader",
        "filename_patterns": [
          "*.npy"
        ],
        "accepts_directories": false
      }
    ],
    "writers": [
      {
        "command": "napari-kld.write_multiple",
        "layer_types": [
          "image*",
          "labels*"
        ],
        "filename_extensions": [],
        "display_name": ""
      },
      {
        "command": "napari-kld.write_single_image",
        "layer_types": [
          "image"
        ],
        "filename_extensions": [
          ".npy"
        ],
        "display_name": ""
      }
    ],
    "widgets": [
      {
        "command": "napari-kld.rldwidget",
        "display_name": "RL Deconvolution",
        "autogenerate": false
      },
      {
        "command": "napari-kld.kldwidget",
        "display_name": "KL Deconvolution",
        "autogenerate": false
      }
    ],
    "sample_data": [
      {
        "command": "napari-kld.make_sample_data",
        "key": "unique_id.1",
        "display_name": "Kernel Learning Deconvolution"
      }
    ],
    "themes": null,
    "menus": {},
    "submenus": null,
    "keybindings": null,
    "configuration": []
  },
  "package_metadata": {
    "metadata_version": "2.1",
    "name": "napari-kld",
    "version": "1.0.0",
    "dynamic": null,
    "platform": null,
    "supported_platform": null,
    "summary": "Kernel learning deconvolution (KLD) is a rapid deconvolution algorithm for fluorescence microscopic image, which learns the forward and backward kernels in Richardson-Lucy Deconvolution (KLD) from paired low-/high-resolution images. ",
    "description": "# napari-kld\n\n[![License](https://img.shields.io/pypi/l/napari-kld.svg?color=green)](https://github.com/qiqi-lu/napari-kld/LICENSE)\n[![PyPI](https://img.shields.io/pypi/v/napari-kld.svg?color=green)](https://pypi.org/project/napari-kld)\n[![Python Version](https://img.shields.io/pypi/pyversions/napari-kld.svg?color=green)](https://python.org)\n[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-kld)](https://napari-hub.org/plugins/napari-kld)\n\n<font color=red> **This plugin is not completed.** </font>\n\n----\n### Kernel Learning Deconvolution (KLD)\n\nKernel learning deconvolution  is a rapid deconvolution algorithm for fluorescence microscopic image, which learns the forward and backward kernels in Richardson-Lucy Deconvolution (KLD) from paired low-/high-resolution images.\n\nIt only requires one sample to training the model, and two iteration to achieve a superior deconvolution perfromance compared to RLD and its variants using unmatched backward projection.\n\n----------------------------------\n\nThis [napari] plugin was generated with [copier] using the [napari-plugin-template].\n\n<!--\nDon't miss the full getting started guide to set up your new package:\nhttps://github.com/napari/napari-plugin-template#getting-started\n\nand review the napari docs for plugin developers:\nhttps://napari.org/stable/plugins/index.html\n-->\n\n## Installation\n\nYou can install `napari-kld` via [pip]:\n\n    pip install napari-kld\n\n\n## Instruction\nThis plugin includes two part:\n\n- `RL Deconvolution` : Conventional RLD algorithm using different type of backward kernels (including matched backward kernel [`Traditional`] and unmatched backward kernels [`Guassian`, `Butterworth`, `Wiener-Butterworth`]). The forward kernel (i.e., PSF) must to be known.\n\n- `KL Deconvolution` : KLD using learned forward/backward kernels.\n\n## RL Deconvolution\n\n## KL Deconvolution\n\n### When only with Point Spread Function (PSF)\n\nWhen you only have a PSF to do deconvolution, you can train the model using simulated data.\n\n1. Generate simulaiton data\n\n2. Train the model under supervised mode\n\n3. Apply the trained model on real data\n\n#### Simulation data generation\n\n1. Load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `KL Deconvolution`\n\n2. Choose `Simulation` tab.\n\n3. Choose the `Output directory` of the generated simulation data, such as `\"napari-kld\\src\\napari_kld\\_tests\\work_directory\\data\\simulation\"`.\n\n4. Choose the `PSF directory` (only support 2D/3D PSF file save as .tif, axes = (z, y, x)), such as `\"D:\\GitHub\\napari-kld\\src\\napari_kld\\_tests\\work_directory\\data\\simulation\\PSF.tif\"`.\n\n5. Adjust the parameters as needed.\n    - `Image shape` : the shape of simulated image, when `z=1`, 2D images will be generated.\n\n    - `PSF crop` : when the input PSF is too large, you can crop the PSF to acuqire a smaller PSF, which is normalized after cropping. All the PSF will be converted to have an odd shape.\n\n    - `Num of simulation` : number of generated images.\n\n    - `Gaussian (std)` : The standard deviation of Gaussian noise added in the generated low-resolution raw images. The mean of Gaussian noise = 0. Default: 0 (i.e., without gaussian noise).\n\n    - `Poisson` : whether to add Poisson noise, if `True`, make the `Enable` checked.\n\n    - `Ratio` : the ratio multiply on ground truth (GT) image to control the level of Poisson noise, thus\n\n    $$ RAW = Possion((GT \\cdot Ratio)\\times PSF) + Gaussian $$\n\n    - `Scale factor` : downsampling scale factor. Default: 1.\n\n6. Press `run` button.\n\n7. Wait the `progress bar` to reach 100%.\n\nThe generated simulation data will be save in `Output directory`, such as: `\"D:\\GitHub\\napari-kld\\src\\napari_kld\\_tests\\work_directory\\data\\simulation\\data\\train\"`\n\n- `\"data\\train\\gt\"` save the GT images.\n- `\"data\\train\\raw\"` save the RAW images with blur and noise.\n- `\"data\\train\\parameters.json\"` is the dictionary of parameter used to generate the simulated data.\n- `\"data\\train\\psf.tif\"` is the psf used in generation of simulation data (as the original PSF may be cropped)\n- `\"data\\train\\train.txt` save all the image used to train the model.\n\n*You may need to adjust the noise level in the image accordding to the real acuqired data.*\n\nAfter you generate simulated data, you can use them to train the model.\n\n#### Training with known PSF and simulated data\n\nThe simulated data should be those generated using the known PSF.\n\n1. Load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `KL Deconvolution`\n\n2. Choose `Training` tab.\n\n3. Choose `Data Directory ` (such as `\"D:/GitHub/napari-kld/src/napari_kld/_tests/work_directory/data/simulation/data/train\"`) which saves the data used to train the model in should include:\n    - A `gt` folder saves the GT images\n    - A `raw` folder save the low-resolution raw input images with the same file name of GT images\n    - A `train.txt` file saves all the file name used to train the model (does not need to list all the file in `gt`/`raw` folder).\n\n4. Choose a `Output Directory` to save the model checkpoints, such as `\"D:/GitHub/napari-kld/src/napari_kld/_tests/work_directory/data/simulation\"`.\n\n5. Choose `PSF Directory` of the PSF used to generate the data, such as `\"D:/GitHub/napari-kld/src/napari_kld/_tests/work_directory/data/simulation/data/train/psf.tif\"`. Then the `Forward Projection` group box will be invisible as we do not need to learn the forward kernel when we know the PSF. Just use the PSF as the froward kernel.\n\n6. Set the `Image Channels` and the `Dimension` of input data.\n\n7. Then set parameters to learn the backward kernel.\n\n    - `Training strategy` : `supervised` training or `self-supervised` training. Set as `supervised`, as we have the GT images.\n    - `Iteration (RL)` : The number of iterations of RL iterative procedure. Default: 2.\n    - `Epoch` : The number fo epochs used to traing the model.\n    - `Batch Size` : The batch size used to training the model.\n    - `Kernel Size (z, xy)`: The size of backward kernel, `x` and `y` have the same size.\n    - `FP directory` : the directory of the forward projeciton model. Here, it is empty (i.e., `\"\"`) as the PSF is known.\n    - `Learning Rate` : The learning rate used to trianing the model.\n\n8. Press `run` button. You can press the `stop` button to end the training.\n\n9. Wait the `progress bar` to reach 100%.\n\n10. Training finished.\n\nWhen the training finished, a checkpoints folder will be created in Ouput Directory such as `\"D:/GitHub/napari-kld/src/napari_kld/_tests/work_directory/data/simulation/checkpoints\"`.\n\nThe models is save in `/checkpoints` folder, which is named as `\"backward_bs_{batch size}_lr_{learning rate}_iter_{num of RL iterations}_ks_{kernel size (z)}_{kernel size (xy)}\"`, such as `\"/checkpoints/backward_bs_1_lr_1e-06_iter_2_ks_1_31\"`, consists of:\n\n- A `log` folder saved the `Tensorboard` log, which can be open with `Tensorboard`.\n- Many model checkpoints, named as `epoch_{epoch}.pt`.\n- A `parameters.json` file saving the parameters used to training the model.\n\n### When only with paired low-resolution (LR) image (as RAW) and high-resolution (HR) image (as GT)\n\nWhen we only have paired LR image and HR image, we can first learned the forward kernel and then learn the backward kernel in a supervised strategy.\n\n#### Training of Forward Projection\n\n1. Load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `KL Deconvolution`\n\n2. Choose `Training` tab.\n\n3. Choose `Data Directory`, such as `\"D:/GitHub/napari-kld/src/napari_kld/_tests/work_directory/data/real/train\"`.\n\n4. Choose `Output Directory`, such as `\"D:/GitHub/napari-kld/src/napari_kld/_tests/work_directory/data/real\"`.\n\n5. `PSF Directory` is no required as the PSF is unknown.\n\n6. Set parameter of parameters about data.\n    - `Image Channel` : the channel of input image.\n    - `Dimension` : dimension of input image.\n\n7. In the `Forward Projection` box, set the parameters of training:\n    - `Epoch` : number of epochs of training.\n    - `Batch Size` : batch size of training data used during training.\n    - `Kernel size (z, xy)` : the size of forward kernel to learned.\n    - `Learning Rate` : learning rate of training.\n\n8. Press `run` button. You can press the `stop` button to end the training.\n\n9. Wait the `progress bar` to reach 100%.\n\n10. Training finished.\n\nAfter the training of forward projection, the results will be save in the `/checkpoints` folder in `Output Directory`, the model was named as `forward_bs_{batch size}_lr_{learning rate}_ks_{kernel size (z)}_{kernel size (xy)}`, such as `\"D:/GitHub/napari-kld/src/napari_kld/_tests/work_directory/data/real/checkpoints/forward_bs_1_lr_0.001_ks_1_31\"`, which consists of:\n- a `log` folder saved the `Tensorboard` log, which can be opened with `Tensorboard`.\n- many model checkpoints, named as `epoch_{epoch}.pt`.\n- a `parameters.json` file saving the parameters used to training the model.\n\n#### Training of Backward Projection\nAfter training of dorward projeciton, we can freeze the forward projeciton and then train the backward projeciton.\n\n1. Load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `KL Deconvolution`\n\n2. Choose `Training` tab.\n\n3. Choose `Data Directory`, such as `\"D:/GitHub/napari-kld/src/napari_kld/_tests/work_directory/data/real/train\"`.\n\n4. Choose `Output Directory`, such as `\"D:/GitHub/napari-kld/src/napari_kld/_tests/work_directory/data/real\"`.\n\n5. `PSF Directory` is no required as the PSF is unknown.\n\n6. set parameter of parameters about data.\n    - `Image Channel` : the channel of input image.\n    - `Dimension` : dimension of input image.\n\n7. In the `Backward Projeciton` box, set parameters for the trianing of backward projeciton.\n\n    - `Training strategy` : `supervised` training or `self-supervised` training. Set as `supervised`, as we have the GT images.\n    - `Iteration (RL)` : The number of iterations of RL iterative procedure. Default: 2.\n    - `Epoch` : The number fo epochs used to traing the model.\n    - `Batch Size` : The batch size used to training the model.\n    - `Kernel Size (z, xy)`: The size of backward kernel, `x` and `y` have the same size.\n    - `FP directory` : the directory of the forward projeciton model, such as `\"D:/GitHub/napari-kld/src/napari_kld/_tests/work_directory/data/real/checkpoints/forward_bs_1_lr_0.001_ks_1_31/epoch_100.pt\"`\n    - `Learning Rate` : The learning rate used to trianing the model.\n\n8. Press `run` button. You can press the `stop` button to end the training.\n\n9. Wait the `progress bar` to reach 100%.\n\n10. Training finished.\n\nWhen the training finishes, the results will be save in the `/checkpoints` folder in `Output Directory`, the model was named as `backward_bs_{batch size}_lr_{learning rate}_iter_{num of RL iterations}_ks_{kernel size (z)}_{kernel size (xy)}`, such as `\"D:/GitHub/napari-kld/src/napari_kld/_tests/work_directory/checkpoints/backward_bs_1_lr_1e-05_iter_2_ks_1_31\"`, which consists of:\n- a `log` folder saved the `Tensorboard` log, which can be opened with `Tensorboard`.\n- many model checkpoints, named as `epoch_{epoch}.pt`.\n- a `parameters.json` file saving the parameters used to training the model.\n\nNow we get the learned forward projection and backward projection.\n\n### When only with LR image and corresponding PSF\nWhen we only have LR image and its PSF, we can traing the backward projection through supervised training using simulation data as introduced above. The plugin also provide an alternative self-supervised training stratergy to learn the backward kernel.\n\n1. load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `KL Deconvolution`\n\n2. choose `Training` tab.\n\n3. choose `Data Directory`, such as `\"D:/GitHub/napari-kld/src/napari_kld/_tests/work_directory/data/real/train\"`.\n\n4. choose `Output Directory`, such as `\"D:/GitHub/napari-kld/src/napari_kld/_tests/work_directory/data/real\"`.\n\n5. choose `PSF Directory`. Now the Forward Projection box will be invisiable.\n\n6. set parameter of parameters about data.\n    - `Image Channel` : the channel of input image.\n    - `Dimension` : dimension of input image.\n\n7. In the `Backward Projeciton` box, set parameters for the trianing of backward projeciton.\n\n    - `Training strategy` : `supervised` training or `self-supervised` training. Set as `self-supervised`, as we do not have the GT images.\n    - `Iteration (RL)` : The number of iterations of RL iterative procedure. Default: 2.\n    - `Epoch` : The number fo epochs used to traing the model.\n    - `Batch Size` : The batch size used to training the model.\n    - `Kernel Size (z, xy)`: The size of backward kernel, `x` and `y` have the same size.\n    - `FP directory` is not required as the PSF is known.\n    - `Learning Rate` : The learning rate used to trianing the model.\n\n8. Press `run` button. You can press the `stop` button to end the training.\n\n9. Wait the `progress bar` to reach 100%.\n\n10. Training finished.\n\nWhen the training finishes, the results will be save in the `/checkpoints` folder in `Output Directory`, the model was named as `backward_bs_{batch size}_lr_{learning rate}_iter_{num of RL iterations}_ks_{kernel size (z)}_{kernel size (xy)}_ss`, such as `\"D:/GitHub/napari-kld/src/napari_kld/_tests/work_directory/checkpoints/backward_bs_1_lr_1e-05_iter_2_ks_31_31_ss\"`, which consists of:\n- a `log` folder saved the `Tensorboard` log, which can be opened with `Tensorboard`.\n- many model checkpoints, named as `epoch_{epoch}.pt`.\n- a `parameters.json` file saving the parameters used to training the model.\n\n### Prediction\nUse the learned forward/backward kernel to do deconvolution.\n\n1. load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `KL Deconvolution`\n\n2. choose `Prediction` tab.\n\n3. load raw input low-resolution image through `napari`: `File` > `Open File(s)` > `[choose the image to be deconvolved]` > `[the image will appear in the layer list of napari]`, such as `\"F:\\Datasets\\BioSR\\F-actin_Nonlinear\\raw_noise_9\\16.tif\"`.\n\n4. choose the loaded image in `Input RAW data` box, e.g., `16`.\n\n5. if the PSF is known, choose the `PSF directory`.\n\n6. if the PSF is unknown, choose the `Forward Projection` directory.*\n\n7. choose the Backward Projeciton directory.\n\n8. set the number of RL iterations at `Iterations (RL)`. Default: 2.\n\n9. Press run to do deconvolution.\n\n10. Wait the progress bar to reach 100%.\n\nThe deconvolved image will directly shwo in the `layer list` of `napari`, named as `\"{input data name}_deconvo_iter_{number of RL iterations}\"`, e.g., `\"16_deconv_iter_2\"`. You can save it as needed.\n\n\n**If both the directories of PSF and Forward Projeciton is choosen, KLD will directly use the PSF selected.*\n\n\n### Others\nThe `log` tab print the message during running.\nPress `clean` button will clean all the text in the `log` box.\n\n### Notice\n- *The training time may be very long if we set the kernel size or the number of epoches too large, especially for 3D images.*\n\n- *Now the plugin is runned on CPU. We have try to run the training on GPU, but the training time did not decrease (maybe it is because the covnlution based on FFT was not optimized on GPU). We are trying to make improvements.*\n\n\n## Contributing\n\nContributions are very welcome. Tests can be run with [tox], please ensure\nthe coverage at least stays the same before you submit a pull request.\n\n## License\n\nMIT LICENSE\n\n## Issues\n\nIf you encounter any problems, please [file an issue] along with a detailed description.\n\n[napari]: https://github.com/napari/napari\n[copier]: https://copier.readthedocs.io/en/stable/\n[@napari]: https://github.com/napari\n[MIT]: http://opensource.org/licenses/MIT\n[BSD-3]: http://opensource.org/licenses/BSD-3-Clause\n[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt\n[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt\n[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0\n[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt\n[napari-plugin-template]: https://github.com/napari/napari-plugin-template\n\n[napari]: https://github.com/napari/napari\n[tox]: https://tox.readthedocs.io/en/latest/\n[pip]: https://pypi.org/project/pip/\n[PyPI]: https://pypi.org/\n",
    "description_content_type": "text/markdown",
    "keywords": null,
    "home_page": null,
    "download_url": null,
    "author": "Qiqi Lu",
    "author_email": "136303971@qq.com",
    "maintainer": null,
    "maintainer_email": null,
    "license": "\nCopyright (c) 2024, Qiqi Lu\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of copyright holder nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "classifier": [
      "Development Status :: 2 - Pre-Alpha",
      "Framework :: napari",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.9",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.11",
      "Programming Language :: Python :: 3.12",
      "Topic :: Scientific/Engineering :: Image Processing"
    ],
    "requires_dist": [
      "numpy ==1.26.4",
      "magicgui",
      "qtpy",
      "scikit-image",
      "torch",
      "torchvision",
      "fft-conv-pytorch",
      "tox ; extra == 'testing'",
      "pytest ; extra == 'testing'",
      "pytest-cov ; extra == 'testing'",
      "pytest-qt ; extra == 'testing'",
      "napari ; extra == 'testing'",
      "pyqt5 ; extra == 'testing'"
    ],
    "requires_python": ">=3.9",
    "requires_external": null,
    "project_url": null,
    "provides_extra": [
      "testing"
    ],
    "provides_dist": null,
    "obsoletes_dist": null
  },
  "npe1_shim": false
}